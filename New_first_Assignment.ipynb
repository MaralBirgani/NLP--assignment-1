{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnahitaNouri/NLP_New_First_Assignment/blob/main/New_first_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6oHfLc4frxQ",
        "outputId": "8c678b62-ba0e-4f39-9522-5d24743faa86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wikipedia-api\n",
            "  Downloading Wikipedia_API-0.6.0-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from wikipedia-api) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->wikipedia-api) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->wikipedia-api) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->wikipedia-api) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->wikipedia-api) (2024.2.2)\n",
            "Installing collected packages: wikipedia-api\n",
            "Successfully installed wikipedia-api-0.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install wikipedia-api"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wikipediaapi\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer, SnowballStemmer, WordNetLemmatizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from nltk import NaiveBayesClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from nltk import classify\n",
        "from nltk import NaiveBayesClassifier"
      ],
      "metadata": {
        "id": "xXO8euv4gOkH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNodLDNnhjm0",
        "outputId": "fc497f5e-2d46-4322-ee2c-91e1770e4fd6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify relevant annotations\n",
        "geographic_keywords = [\"location\", \"geography\", \"map\", \"country\", \"city\"]\n",
        "non_geographic_keywords = [\"technology\", \"science\", \"artificial intelligence\", \"computer\"]"
      ],
      "metadata": {
        "id": "YCAPRWSRaNsO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_wikipedia_text_with_annotations(topic, keyword_list):\n",
        "    # Create a Wikipedia API object\n",
        "    wiki_wiki = wikipediaapi.Wikipedia('en', extract_format=wikipediaapi.ExtractFormat.WIKI, headers={'User-Agent': 'Anahita'})\n",
        "\n",
        "    # Fetch the page for the given topic\n",
        "    page = wiki_wiki.page(topic)\n",
        "\n",
        "    if page.exists():\n",
        "        # Retrieve the text content of the page\n",
        "        text = page.text\n",
        "\n",
        "        # Extract annotations or keywords from the text\n",
        "        annotations = [keyword for keyword in keyword_list if keyword.lower() in text.lower()]\n",
        "\n",
        "        return text, annotations\n",
        "    else:\n",
        "        print(f\"Page for topic '{topic}' does not exist.\")\n",
        "        return None, None\n",
        "\n",
        "# Fetch the content of Wikipedia page with annotations\n",
        "topic = \"Artificial intelligence\"\n",
        "text, annotations = fetch_wikipedia_text_with_annotations(topic, non_geographic_keywords)\n",
        "\n",
        "if text:\n",
        "    print(f\"Text content for '{topic}':\")\n",
        "    print(text[:500])  # Print the first 500 characters of the text\n",
        "    print(\"Annotations:\", annotations)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBOI1GfKg7qA",
        "outputId": "0a82c3ab-e4cf-4af3-d2f0-84276c4b434f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text content for 'Artificial intelligence':\n",
            "Artificial intelligence (AI) is the intelligence of machines or software, as opposed to the intelligence of humans or other living beings. It is a field of study in computer science that develops and studies intelligent machines. Such machines may be called AIs.\n",
            "AI technology is widely used throughout industry, government, and science. Some high-profile applications are: advanced web search engines (e.g., Google Search), recommendation systems (used by YouTube, Amazon, and Netflix), interacting \n",
            "Annotations: ['technology', 'science', 'artificial intelligence', 'computer']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text_with_annotations(text, annotations, stop_words=None, stemmer=None, lemmatizer=None):\n",
        "    # Tokenize the text\n",
        "    words = word_tokenize(text)\n",
        "\n",
        "    # Use Snowball stop words if provided, otherwise use NLTK default stop words\n",
        "    stop_words = stop_words or set(stopwords.words('english'))\n",
        "\n",
        "    # Remove stop words\n",
        "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
        "\n",
        "    # Use Snowball stemmer if provided, otherwise use Porter Stemmer\n",
        "    stemmer = stemmer or PorterStemmer()\n",
        "    stemmed_words = [stemmer.stem(word) for word in filtered_words]\n",
        "\n",
        "    # Use WordNet Lemmatizer if provided, otherwise use a basic lemmatizer\n",
        "    lemmatizer = lemmatizer or WordNetLemmatizer()\n",
        "    lemmatized_words = [lemmatizer.lemmatize(word) for word in stemmed_words]\n",
        "\n",
        "    # Join the preprocessed words back into a single string\n",
        "    preprocessed_text = ' '.join(lemmatized_words)\n",
        "\n",
        "    # Incorporate annotations into the preprocessed text\n",
        "    preprocessed_text += ' '.join(annotations)\n",
        "\n",
        "    return preprocessed_text\n",
        "\n",
        "\n",
        "# Usage with Bag of Words without pre-processing\n",
        "bag_of_words_text = text.lower()\n",
        "bag_of_words_features = {word: True for word in word_tokenize(bag_of_words_text)}\n",
        "\n",
        "# Usage with Snowball stop word list and Porter Stemmer\n",
        "snowball_stemmer = SnowballStemmer('english')\n",
        "preprocessed_snowball_text = preprocess_text_with_annotations(text, annotations, stop_words=set(stopwords.words('english')), stemmer=snowball_stemmer)\n",
        "\n",
        "# Usage with WordNet Lemmatizer\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "preprocessed_lemmatized_text = preprocess_text_with_annotations(text, annotations, stop_words=set(stopwords.words('english')), lemmatizer=wordnet_lemmatizer)\n",
        "\n",
        "# Display the results\n",
        "print(\"\\nBag of Words without pre-processing:\")\n",
        "print(bag_of_words_features)\n",
        "\n",
        "print(\"\\nPreprocessed Text with Snowball stop words and Porter Stemmer:\")\n",
        "print(preprocessed_snowball_text[:500])\n",
        "\n",
        "print(\"\\nPreprocessed Text with WordNet Lemmatizer:\")\n",
        "print(preprocessed_lemmatized_text[:500])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izHcvkgohRdE",
        "outputId": "bf890afb-5be2-4b71-a60c-7c9d30089b81"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Bag of Words without pre-processing:\n",
            "{'artificial': True, 'intelligence': True, '(': True, 'ai': True, ')': True, 'is': True, 'the': True, 'of': True, 'machines': True, 'or': True, 'software': True, ',': True, 'as': True, 'opposed': True, 'to': True, 'humans': True, 'other': True, 'living': True, 'beings': True, '.': True, 'it': True, 'a': True, 'field': True, 'study': True, 'in': True, 'computer': True, 'science': True, 'that': True, 'develops': True, 'and': True, 'studies': True, 'intelligent': True, 'such': True, 'may': True, 'be': True, 'called': True, 'ais': True, 'technology': True, 'widely': True, 'used': True, 'throughout': True, 'industry': True, 'government': True, 'some': True, 'high-profile': True, 'applications': True, 'are': True, ':': True, 'advanced': True, 'web': True, 'search': True, 'engines': True, 'e.g.': True, 'google': True, 'recommendation': True, 'systems': True, 'by': True, 'youtube': True, 'amazon': True, 'netflix': True, 'interacting': True, 'via': True, 'human': True, 'speech': True, 'assistant': True, 'siri': True, 'alexa': True, 'self-driving': True, 'cars': True, 'waymo': True, 'generative': True, 'creative': True, 'tools': True, 'chatgpt': True, 'art': True, 'superhuman': True, 'play': True, 'analysis': True, 'strategy': True, 'games': True, 'chess': True, 'go': True, '.alan': True, 'turing': True, 'was': True, 'first': True, 'person': True, 'conduct': True, 'substantial': True, 'research': True, 'he': True, 'machine': True, 'founded': True, 'an': True, 'academic': True, 'discipline': True, '1956.': True, 'went': True, 'through': True, 'multiple': True, 'cycles': True, 'optimism': True, 'followed': True, 'disappointment': True, 'loss': True, 'funding': True, 'interest': True, 'vastly': True, 'increased': True, 'after': True, '2012': True, 'when': True, 'deep': True, 'learning': True, 'surpassed': True, 'all': True, 'previous': True, 'techniques': True, '2017': True, 'with': True, 'transformer': True, 'architecture': True, 'this': True, 'led': True, 'spring': True, 'early': True, '2020s': True, 'companies': True, 'universities': True, 'laboratories': True, 'overwhelmingly': True, 'based': True, 'united': True, 'states': True, 'pioneering': True, 'significant': True, 'advances': True, 'intelligence.the': True, 'various': True, 'sub-fields': True, 'centered': True, 'around': True, 'particular': True, 'goals': True, 'use': True, 'traditional': True, 'include': True, 'reasoning': True, 'knowledge': True, 'representation': True, 'planning': True, 'natural': True, 'language': True, 'processing': True, 'perception': True, 'support': True, 'for': True, 'robotics': True, 'general': True, 'ability': True, 'complete': True, 'any': True, 'task': True, 'performable': True, 'among': True, \"'s\": True, 'long-term': True, 'goals.to': True, 'solve': True, 'these': True, 'problems': True, 'researchers': True, 'have': True, 'adapted': True, 'integrated': True, 'wide': True, 'range': True, 'problem-solving': True, 'including': True, 'mathematical': True, 'optimization': True, 'formal': True, 'logic': True, 'neural': True, 'networks': True, 'methods': True, 'on': True, 'statistics': True, 'operations': True, 'economics': True, 'also': True, 'draws': True, 'upon': True, 'psychology': True, 'linguistics': True, 'philosophy': True, 'neuroscience': True, 'fields': True, 'problem': True, 'simulating': True, 'creating': True, 'has': True, 'been': True, 'broken': True, 'into': True, 'sub-problems': True, 'consist': True, 'traits': True, 'capabilities': True, 'expect': True, 'system': True, 'display': True, 'described': True, 'below': True, 'received': True, 'most': True, 'attention': True, 'cover': True, 'scope': True, 'developed': True, 'algorithms': True, 'imitated': True, 'step-by-step': True, 'they': True, 'puzzles': True, 'make': True, 'logical': True, 'deductions': True, 'late': True, '1980s': True, '1990s': True, 'were': True, 'dealing': True, 'uncertain': True, 'incomplete': True, 'information': True, 'employing': True, 'concepts': True, 'from': True, 'probability': True, 'economics.many': True, 'insufficient': True, 'solving': True, 'large': True, 'because': True, 'experience': True, '``': True, 'combinatorial': True, 'explosion': True, \"''\": True, 'became': True, 'exponentially': True, 'slower': True, 'grew': True, 'larger': True, 'even': True, 'rarely': True, 'deduction': True, 'could': True, 'model': True, 'their': True, 'using': True, 'fast': True, 'intuitive': True, 'judgments': True, 'accurate': True, 'efficient': True, 'unsolved': True, 'engineering': True, 'allow': True, 'programs': True, 'answer': True, 'questions': True, 'intelligently': True, 'about': True, 'real-world': True, 'facts': True, 'representations': True, 'content-based': True, 'indexing': True, 'retrieval': True, 'scene': True, 'interpretation': True, 'clinical': True, 'decision': True, 'discovery': True, 'mining': True, 'interesting': True, 'actionable': True, 'inferences': True, 'databases': True, 'areas.a': True, 'base': True, 'body': True, 'represented': True, 'form': True, 'can': True, 'program': True, 'ontology': True, 'set': True, 'objects': True, 'relations': True, 'properties': True, 'domain': True, 'bases': True, 'need': True, 'represent': True, 'things': True, 'categories': True, 'between': True, ';': True, 'situations': True, 'events': True, 'time': True, 'causes': True, 'effects': True, 'what': True, 'we': True, 'know': True, 'people': True, 'default': True, 'assume': True, 'true': True, 'until': True, 'told': True, 'differently': True, 'will': True, 'remain': True, 'changing': True, 'many': True, 'aspects': True, 'domains': True, 'difficult': True, 'breadth': True, 'commonsense': True, 'atomic': True, 'average': True, 'knows': True, 'enormous': True, 'sub-symbolic': True, 'much': True, 'not': True, 'statements': True, 'express': True, 'verbally': True, 'there': True, 'difficulty': True, 'acquisition': True, 'obtaining': True, 'making': True, 'agent': True, 'anything': True, 'perceives': True, 'takes': True, 'actions': True, 'world': True, 'rational': True, 'preferences': True, 'them': True, 'happen': True, 'automated': True, 'specific': True, 'goal': True, '–': True, 'would': True, 'prefer': True, 'trying': True, 'avoid': True, 'assigns': True, 'number': True, 'each': True, 'situation': True, 'utility': True, 'measures': True, 'how': True, 'prefers': True, 'possible': True, 'action': True, 'calculate': True, 'expected': True, 'outcomes': True, 'weighted': True, 'outcome': True, 'occur': True, 'then': True, 'choose': True, 'maximum': True, 'utility.in': True, 'classical': True, 'exactly': True, 'effect': True, 'however': True, 'certain': True, 'unknown': True, 'unobservable': True, 'deterministic': True, 'must': True, 'probabilistic': True, 'guess': True, 'reassess': True, 'see': True, 'if': True, 'worked.in': True, 'especially': True, 'agents': True, 'involved': True, 'learned': True, 'inverse': True, 'reinforcement': True, 'seek': True, 'improve': True, 'its': True, 'value': True, 'theory': True, 'weigh': True, 'exploratory': True, 'experimental': True, 'space': True, 'future': True, 'typically': True, 'intractably': True, 'so': True, 'take': True, 'evaluate': True, 'while': True, 'being': True, 'markov': True, 'process': True, 'transition': True, 'describes': True, 'change': True, 'state': True, 'way': True, 'reward': True, 'function': True, 'supplies': True, 'cost': True, 'policy': True, 'associates': True, 'calculated': True, 'e.g': True, 'iteration': True, 'heuristic': True, 'learned.game': True, 'behavior': True, 'decisions': True, 'involve': True, 'performance': True, 'given': True, 'automatically': True, 'part': True, 'beginning.there': True, 'several': True, 'kinds': True, 'unsupervised': True, 'analyzes': True, 'stream': True, 'data': True, 'finds': True, 'patterns': True, 'makes': True, 'predictions': True, 'without': True, 'guidance': True, 'supervised': True, 'requires': True, 'label': True, 'input': True, 'comes': True, 'two': True, 'main': True, 'varieties': True, 'classification': True, 'where': True, 'learn': True, 'predict': True, 'category': True, 'belongs': True, 'regression': True, 'deduce': True, 'numeric': True, '.in': True, 'rewarded': True, 'good': True, 'responses': True, 'punished': True, 'bad': True, 'ones': True, 'learns': True, 'classified': True, 'transfer': True, 'gained': True, 'one': True, 'applied': True, 'new': True, 'type': True, 'runs': True, 'inputs': True, 'biologically': True, 'inspired': True, 'types': True, 'learning.computational': True, 'assess': True, 'learners': True, 'computational': True, 'complexity': True, 'sample': True, 'required': True, 'notions': True, 'nlp': True, 'allows': True, 'read': True, 'write': True, 'communicate': True, 'languages': True, 'english': True, 'recognition': True, 'synthesis': True, 'translation': True, 'extraction': True, 'question': True, 'answering.early': True, 'work': True, 'noam': True, 'chomsky': True, 'grammar': True, 'semantic': True, 'had': True, 'word-sense': True, 'disambiguation': True, 'unless': True, 'restricted': True, 'small': True, 'micro-worlds': True, 'due': True, 'common': True, 'sense': True, 'margaret': True, 'masterman': True, 'believed': True, 'meaning': True, 'key': True, 'understanding': True, 'thesauri': True, 'dictionaries': True, 'should': True, 'basis': True, 'structure': True, 'modern': True, 'word': True, 'embedding': True, 'representing': True, 'words': True, 'vectors': True, 'encoding': True, 'transformers': True, 'mechanism': True, 'others': True, '2019': True, 'pre-trained': True, 'gpt': True, 'models': True, 'began': True, 'generate': True, 'coherent': True, 'text': True, '2023': True, 'able': True, 'get': True, 'human-level': True, 'scores': True, 'bar': True, 'exam': True, 'sat': True, 'test': True, 'gre': True, 'sensors': True, 'cameras': True, 'microphones': True, 'wireless': True, 'signals': True, 'active': True, 'lidar': True, 'sonar': True, 'radar': True, 'tactile': True, 'vision': True, 'analyze': True, 'visual': True, 'input.the': True, 'includes': True, 'image': True, 'facial': True, 'object': True, 'robotic': True, 'social': True, 'affective': True, 'computing': True, 'interdisciplinary': True, 'umbrella': True, 'comprises': True, 'recognize': True, 'interpret': True, 'simulate': True, 'feeling': True, 'emotion': True, 'mood': True, 'example': True, 'virtual': True, 'assistants': True, 'programmed': True, 'speak': True, 'conversationally': True, 'banter': True, 'humorously': True, 'appear': True, 'more': True, 'sensitive': True, 'emotional': True, 'dynamics': True, 'interaction': True, 'otherwise': True, 'facilitate': True, 'human–computer': True, 'tends': True, 'give': True, 'naïve': True, 'users': True, 'unrealistic': True, 'conception': True, 'existing': True, 'moderate': True, 'successes': True, 'related': True, 'textual': True, 'sentiment': True, 'recently': True, 'multimodal': True, 'wherein': True, 'classifies': True, 'affects': True, 'displayed': True, 'videotaped': True, 'subject': True, 'variety': True, 'versatility': True, 'similar': True, 'uses': True, 'accomplish': True, 'above': True, 'searching': True, 'solutions': True, 'very': True, 'different': True, 'local': True, 'searches': True, 'tree': True, 'try': True, 'find': True, 'trees': True, 'subgoals': True, 'attempting': True, 'path': True, 'target': True, 'means-ends': True, 'analysis.simple': True, 'exhaustive': True, 'sufficient': True, 'places': True, 'quickly': True, 'grows': True, 'astronomical': True, 'numbers': True, 'result': True, 'too': True, 'slow': True, 'never': True, 'completes': True, 'heuristics': True, 'rules': True, 'thumb': True, 'help': True, 'prioritize': True, 'choices': True, 'likely': True, 'reach': True, 'goal.adversarial': True, 'game-playing': True, 'moves': True, 'counter-moves': True, 'looking': True, 'winning': True, 'position': True, 'solution': True, 'begins': True, 'refines': True, 'incrementally.gradient': True, 'descent': True, 'optimizes': True, 'numerical': True, 'parameters': True, 'incrementally': True, 'adjusting': True, 'minimize': True, 'variants': True, 'gradient': True, 'commonly': True, 'train': True, 'networks.another': True, 'evolutionary': True, 'computation': True, 'which': True, 'aims': True, 'iteratively': True, 'candidate': True, 'mutating': True, 'recombining': True, 'selecting': True, 'only': True, 'fittest': True, 'survive': True, 'generation.distributed': True, 'processes': True, 'coordinate': True, 'swarm': True, 'popular': True, 'particle': True, 'bird': True, 'flocking': True, 'ant': True, 'colony': True, 'trails': True, 'forms': True, 'propositional': True, 'operates': True, 'false': True, 'connectives': True, 'implies': True, 'predicate': True, 'predicates': True, 'quantifiers': True, 'every': True, 'x': True, 'y': True, 'xs': True, 'ys': True, '.logical': True, 'inference': True, 'proving': True, 'statement': True, 'conclusion': True, 'already': True, 'known': True, 'premises': True, 'handles': True, 'queries': True, 'assertions': True, 'special': True, 'case': True, 'rule': True, 'valid': True, 'step': True, 'proof': True, 'resolution': True, 'reduced': True, 'performing': True, 'leads': True, 'conclusions': True, 'application': True, 'performed': True, 'intractable': True, 'except': True, 'short': True, 'proofs': True, 'no': True, 'powerful': True, 'method': True, 'discovered': True, 'fuzzy': True, 'degree': True, 'truth': True, '0': True, '1.': True, 'therefore': True, 'handle': True, 'propositions': True, 'vague': True, 'partially': True, 'true.non-monotonic': True, 'logics': True, 'designed': True, 'specialized': True, 'versions': True, 'describe': True, 'complex': True, 'require': True, 'operate': True, 'devised': True, 'economics.bayesian': True, 'tool': True, 'bayesian': True, 'algorithm': True, 'expectation-maximization': True, 'dynamic': True, '.probabilistic': True, 'filtering': True, 'prediction': True, 'smoothing': True, 'finding': True, 'explanations': True, 'streams': True, 'helping': True, 'over': True, 'hidden': True, 'kalman': True, 'filters': True, 'precise': True, 'plan': True, 'game': True, 'design': True, 'classifiers': True, 'statistical': True, 'simplest': True, 'divided': True, 'shiny': True, 'diamond': True, 'hand': True, 'controllers': True, 'pick': True, 'up': True, 'functions': True, 'pattern': True, 'matching': True, 'determine': True, 'closest': True, 'match': True, 'fine-tuned': True, 'chosen': True, 'examples': True, 'observation': True, 'labeled': True, 'predefined': True, 'class': True, 'observations': True, 'combined': True, 'labels': True, 'experience.there': True, 'symbolic': True, 'k-nearest': True, 'neighbor': True, 'analogical': True, 'mid-1990s': True, 'kernel': True, 'vector': True, 'svm': True, 'displaced': True, 'naive': True, 'bayes': True, 'classifier': True, 'reportedly': True, 'learner': True, 'at': True, 'scalability.neural': True, 'network': True, 'collection': True, 'nodes': True, 'neurons': True, 'loosely': True, 'biological': True, 'brain': True, 'trained': True, 'recognise': True, 'once': True, 'those': True, 'fresh': True, 'least': True, 'layer': True, 'output': True, 'node': True, 'applies': True, 'weight': True, 'crosses': True, 'specified': True, 'threshold': True, 'transmitted': True, 'next': True, '2': True, 'layers.learning': True, 'weights': True, 'right': True, 'during': True, 'training': True, 'technique': True, 'backpropagation': True, 'relationships': True, 'outputs': True, 'function.in': True, 'feedforward': True, 'signal': True, 'passes': True, 'direction.recurrent': True, 'feed': True, 'back': True, 'short-term': True, 'memories': True, 'long': True, 'term': True, 'memory': True, 'successful': True, 'recurrent': True, 'networks.perceptrons': True, 'single': True, 'layers': True, 'convolutional': True, 'strengthen': True, 'connection': True, 'close': True, 'important': True, 'identify': True, 'edge': True, 'before': True, 'progressively': True, 'extract': True, 'higher-level': True, 'features': True, 'raw': True, 'lower': True, 'edges': True, 'higher': True, 'relevant': True, 'digits': True, 'letters': True, 'faces.deep': True, 'profoundly': True, 'improved': True, 'subfields': True, 'reason': True, 'performs': True, 'well': True, '2023.': True, 'sudden': True, 'success': True, '2012–2015': True, 'did': True, 'theoretical': True, 'breakthrough': True, 'far': True, '1950s': True, 'but': True, 'factors': True, 'incredible': True, 'increase': True, 'power': True, 'hundred-fold': True, 'speed': True, 'switching': True, 'gpus': True, 'availability': True, 'vast': True, 'amounts': True, 'giant': True, 'curated': True, 'datasets': True, 'benchmark': True, 'testing': True, 'imagenet': True, 'sentences': True, 'text-based': True, 'corpus': True, 'internet': True, 'pre-training': True, 'consists': True, 'predicting': True, 'token': True, 'usually': True, 'subword': True, 'punctuation': True, 'accumulate': True, 'human-like': True, 'repeatedly': True, 'subsequent': True, 'phase': True, 'truthful': True, 'useful': True, 'harmless': True, 'feedback': True, 'rlhf': True, 'current': True, 'still': True, 'prone': True, 'generating': True, 'falsehoods': True, 'hallucinations': True, 'although': True, 'quality': True, 'chatbots': True, 'you': True, 'ask': True, 'request': True, 'simple': True, 'text.current': True, 'services': True, 'bard': True, 'grok': True, 'claude': True, 'copilot': True, 'llama': True, 'modalities': True, 'images': True, 'videos': True, 'sound': True, 'hardware': True, '2010s': True, 'graphics': True, 'units': True, 'increasingly': True, 'ai-specific': True, 'enhancements': True, 'tensorflow': True, 'replaced': True, 'previously': True, 'central': True, 'unit': True, 'cpus': True, 'dominant': True, 'means': True, 'large-scale': True, 'commercial': True, \"'\": True, 'historically': True, 'lisp': True, 'prolog': True, 'python': True, 'essential': True, 'targeting': True, 'online': True, 'advertisements': True, 'offered': True, 'driving': True, 'traffic': True, 'targeted': True, 'advertising': True, 'adsense': True, 'facebook': True, 'autonomous': True, 'vehicles': True, 'drones': True, 'adas': True, 'automatic': True, 'microsoft': True, 'translator': True, 'translate': True, 'apple': True, 'face': True, 'id': True, 'deepface': True, 'facenet': True, 'labeling': True, 'iphoto': True, 'tiktok': True, 'health': True, 'medicine': True, 'medical': True, 'potential': True, 'patient': True, 'care': True, 'life': True, 'lens': True, 'hippocratic': True, 'oath': True, 'professionals': True, 'ethically': True, 'compelled': True, 'accurately': True, 'diagnose': True, 'treat': True, 'patients': True, 'integrating': True, 'big': True, 'particularly': True, 'organoid': True, 'tissue': True, 'development': True, 'microscopy': True, 'imaging': True, 'fabrication': True, 'suggested': True, 'overcome': True, 'discrepancies': True, 'allocated': True, 'deepen': True, 'our': True, 'biomedically': True, 'pathways': True, 'alphafold': True, '2021': True, 'demonstrated': True, 'approximate': True, 'hours': True, 'rather': True, 'than': True, 'months': True, '3d': True, 'protein': True, 'reported': True, 'guided': True, 'drug': True, 'helped': True, 'antibiotics': True, 'capable': True, 'killing': True, 'drug-resistant': True, 'bacteria': True, 'playing': True, 'since': True, 'demonstrate': True, 'blue': True, 'chess-playing': True, 'beat': True, 'reigning': True, 'champion': True, 'garry': True, 'kasparov': True, '11': True, '1997.': True, '2011': True, 'jeopardy': True, '!': True, 'quiz': True, 'show': True, 'exhibition': True, 'ibm': True, 'answering': True, 'watson': True, 'defeated': True, 'greatest': True, 'champions': True, 'brad': True, 'rutter': True, 'ken': True, 'jennings': True, 'margin': True, 'march': True, '2016': True, 'alphago': True, 'won': True, '4': True, 'out': True, '5': True, 'lee': True, 'sedol': True, 'becoming': True, 'go-playing': True, 'professional': True, 'player': True, 'handicaps': True, 'ke': True, 'jie': True, 'who': True, 'best': True, 'imperfect-information': True, 'poker-playing': True, 'pluribus': True, 'deepmind': True, 'generalistic': True, 'reinfrocement': True, 'muzero': True, 'atari': True, 'alphastar': True, 'achieved': True, 'grandmaster': True, 'level': True, 'starcraft': True, 'ii': True, 'challenging': True, 'real-time': True, 'involves': True, 'happens': True, 'map': True, 'competed': True, 'playstation': True, 'gran': True, 'turismo': True, 'competition': True, 'against': True, 'four': True, '’': True, 's': True, 'drivers': True, 'military': True, 'countries': True, 'deploying': True, 'enhance': True, 'command': True, 'control': True, 'communications': True, 'integration': True, 'interoperability': True, 'logistics': True, 'cyber': True, 'semiautonomous': True, 'technologies': True, 'enable': True, 'coordination': True, 'effectors': True, 'threat': True, 'detection': True, 'identification': True, 'marking': True, 'enemy': True, 'positions': True, 'deconfliction': True, 'distributed': True, 'joint': True, 'fires': True, 'networked': True, 'combat': True, 'involving': True, 'manned': True, 'unmanned': True, 'teams': True, 'incorporated': True, 'iraq': True, 'syria': True, 'november': True, 'us': True, 'vice': True, 'president': True, 'kamala': True, 'harris': True, 'disclosed': True, 'declaration': True, 'signed': True, '31': True, 'nations': True, 'guardrails': True, 'ia': True, 'commitments': True, 'legal': True, 'reviews': True, 'ensure': True, 'compliance': True, 'international': True, 'laws': True, 'cautious': True, 'transparent': True, 'widespread': True, 'prominence': True, '58': True, '%': True, 'adults': True, 'heard': True, '14': True, 'tried': True, 'increasing': True, 'realism': True, 'ease-of-use': True, 'ai-based': True, 'text-to-image': True, 'generators': True, 'midjourney': True, 'dall-e': True, 'stable': True, 'diffusion': True, 'sparked': True, 'trend': True, 'viral': True, 'ai-generated': True, 'photos': True, 'fake': True, 'photo': True, 'pope': True, 'francis': True, 'wearing': True, 'white': True, 'puffer': True, 'coat': True, 'fictional': True, 'arrest': True, 'donald': True, 'trump': True, 'hoax': True, 'attack': True, 'pentagon': True, 'usage': True, 'arts': True, 'tasks': True, 'thousands': True, 'industries': True, 'institutions': True, 'survey': True, 'five': True, 'offerings': True, 'few': True, 'energy': True, 'storage': True, 'diagnosis': True, 'judicial': True, 'foreign': True, 'supply': True, 'chain': True, 'management': True, 'agriculture': True, 'farmers': True, 'areas': True, 'irrigation': True, 'fertilization': True, 'pesticide': True, 'treatments': True, 'yield': True, 'agronomists': True, 'ripening': True, 'crops': True, 'tomatoes': True, 'monitor': True, 'soil': True, 'moisture': True, 'agricultural': True, 'robots': True, 'predictive': True, 'analytics': True, 'classify': True, 'livestock': True, 'pig': True, 'call': True, 'emotions': True, 'automate': True, 'greenhouses': True, 'detect': True, 'diseases': True, 'pests': True, 'save': True, 'water': True, 'astronomy': True, 'available': True, 'mainly': True, 'clustering': True, 'forecasting': True, 'generation': True, 'scientific': True, 'insights': True, 'discovering': True, 'exoplanets': True, 'solar': True, 'activity': True, 'distinguishing': True, 'instrumental': True, 'gravitational': True, 'wave': True, 'activities': True, 'exploration': True, 'missions': True, 'spacecraft': True, 'debris': True, 'avoidance': True, 'operation': True, 'ethics': True, 'like': True, 'benefits': True, 'risks': True, 'advance': True, 'serious': True, 'demis': True, 'hassabis': True, 'mind': True, 'hopes': True, 'everything': True, 'else': True, 'become': True, 'unintended': True, 'consequences': True, 'identified.anyone': True, 'in-production': True, 'needs': True, 'factor': True, 'strive': True, 'bias': True, 'inherently': True, 'unexplainable': True, 'harm': True, 'privacy': True, 'copyright': True, 'acquire': True, 'raised': True, 'concerns': True, 'surveillance': True, 'collect': True, 'geolocation': True, 'video': True, 'audio': True, 'order': True, 'build': True, 'recorded': True, 'millions': True, 'private': True, 'conversations': True, 'allowed': True, 'temps': True, 'listen': True, 'transcribe': True, 'opinions': True, 'necessary': True, 'evil': True, 'whom': True, 'clearly': True, 'unethical': True, 'violation': True, 'privacy.ai': True, 'developers': True, 'argue': True, 'deliver': True, 'valuable': True, 'attempt': True, 'preserve': True, 'aggregation': True, 'de-identification': True, 'differential': True, 'experts': True, 'cynthia': True, 'dwork': True, 'view': True, 'terms': True, 'fairness': True, 'brian': True, 'christian': True, 'wrote': True, 'pivoted': True, \"'what\": True, \"'re\": True, 'doing': True, '.generative': True, 'often': True, 'unlicensed': True, 'copyrighted': True, 'works': True, 'code': True, 'under': True, 'rationale': True, 'fair': True, 'website': True, 'owners': True, 'do': True, 'wish': True, 'content': True, 'indexed': True, '‘': True, 'scraped': True, 'add': True, 'site': True, 'want': True, 'your': True, 'engine': True, 'currently': True, 'openai': True, 'disagree': True, 'circumstances': True, 'hold': True, 'courts': True, 'law': True, 'purpose': True, 'character': True, 'market': True, 'leading': True, 'authors': True, 'john': True, 'grisham': True, 'jonathan': True, 'franzen': True, 'sued': True, 'misinformation': True, 'recommender': True, 'guide': True, 'maximizing': True, 'user': True, 'engagement': True, 'keep': True, 'watching': True, 'tended': True, 'conspiracy': True, 'theories': True, 'extreme': True, 'partisan': True, 'recommended': True, 'watch': True, 'same': True, 'filter': True, 'bubbles': True, 'convinced': True, 'ultimately': True, 'undermined': True, 'trust': True, 'media': True, 'correctly': True, 'maximize': True, 'harmful': True, 'society': True, 'u.s.': True, 'election': True, 'major': True, 'took': True, 'steps': True, 'mitigate': True, '2022': True, 'create': True, 'indistinguishable': True, 'real': True, 'photographs': True, 'recordings': True, 'films': True, 'writing': True, 'actors': True, 'massive': True, 'propaganda': True, 'pioneer': True, 'geoffrey': True, 'hinton': True, 'expressed': True, 'concern': True, 'enabling': True, 'authoritarian': True, 'leaders': True, 'manipulate': True, 'electorates': True, 'scale': True, 'algorithmic': True, 'biased': True, 'aware': True, 'exists': True, 'introduced': True, 'selected': True, 'deployed': True, 'seriously': True, 'finance': True, 'recruitment': True, 'housing': True, 'policing': True, 'cause': True, 'discrimination.fairness': True, 'prevent': True, 'caused': True, 'area': True, 'within': True, 'always': True, 'define': True, 'satisfies': True, 'stakeholders.on': True, 'june': True, '28': True, '2015': True, 'feature': True, 'mistakenly': True, 'identified': True, 'jacky': True, 'alcine': True, 'friend': True, 'gorillas': True, 'black': True, 'dataset': True, 'contained': True, 'size': True, 'disparity': True, 'fixed': True, 'preventing': True, 'labelling': True, 'gorilla': True, 'eight': True, 'years': True, 'later': True, 'neither': True, 'products': True, 'amazon.compas': True, 'likelihood': True, 'defendant': True, 'recidivist': True, 'julia': True, 'angwin': True, 'propublica': True, 'compas': True, 'exhibited': True, 'racial': True, 'despite': True, 'fact': True, 'races': True, 'defendants': True, 'error': True, 'rate': True, 'both': True, 'whites': True, 'blacks': True, 'calibrated': True, 'equal': True, '61': True, 'errors': True, 'race': True, 'different—the': True, 'consistently': True, 'overestimated': True, 'chance': True, 're-offend': True, 'underestimate': True, 'showed': True, 'mathematically': True, 'impossible': True, 'accommodate': True, 'rates': True, 're-offense': True, 'data.a': True, 'does': True, 'explicitly': True, 'mention': True, 'problematic': True, 'gender': True, 'correlate': True, 'address': True, 'shopping': True, 'history': True, 'name': True, 'moritz': True, 'hardt': True, 'said': True, 'robust': True, 'blindness': True, \"n't\": True, 'criticism': True, 'highlighted': True, 'deeper': True, 'misuse': True, 'resemble': True, 'past': True, 'results': True, 'racist': True, 'made': True, 'unfortunately': True, 'recommendations': True, 'thus': True, 'suited': True, 'hope': True, 'better': True, 'necessarily': True, 'descriptive': True, 'proscriptive.bias': True, 'unfairness': True, 'undetected': True, 'male': True, 'engineers': True, '20': True, 'women.at': True, 'conference': True, 'accountability': True, 'transparency': True, 'acm': True, 'facct': True, 'association': True, 'machinery': True, 'seoul': True, 'south': True, 'korea': True, 'presented': True, 'published': True, 'findings': True, 'recommending': True, 'free': True, 'mistakes': True, 'unsafe': True, 'self-learning': True, 'unregulated': True, 'sources': True, 'flawed': True, 'curtailed': True, 'lack': True, 'designers': True, 'explain': True, 'amount': True, 'non-linear': True, 'explainability': True, 'exist.there': True, 'cases': True, 'passed': True, 'rigorous': True, 'tests': True, 'nevertheless': True, 'something': True, 'programmers': True, 'intended': True, 'skin': True, 'found': True, 'actually': True, 'strong': True, 'tendency': True, 'ruler': True, 'cancerous': True, 'pictures': True, 'malignancies': True, 'another': True, 'effectively': True, 'allocate': True, 'resources': True, 'asthma': True, 'low': True, 'risk': True, 'dying': True, 'pneumonia': True, 'having': True, 'severe': True, 'relatively': True, 'unlikely': True, 'die': True, 'according': True, 'correlation': True, 'misleading.people': True, 'harmed': True, 'explanation': True, 'doctors': True, 'completely': True, 'behind': True, 'drafts': True, 'european': True, 'union': True, 'protection': True, 'regulation': True, 'included': True, 'explicit': True, 'noted': True, 'sight': True, 'regulators': True, 'argued': True, 'used.darpa': True, 'established': True, 'xai': True, 'explainable': True, '2014': True, 'problems.there': True, 'shap': True, 'helps': True, 'visualise': True, 'contribution': True, 'lime': True, 'locally': True, 'simpler': True, 'interpretable': True, 'multitask': True, 'provides': True, 'addition': True, 'deconvolution': True, 'deepdream': True, 'produce': True, 'suggest': True, 'conflict': True, 'weaponized': True, 'lethal': True, 'weapon': True, 'locates': True, 'selects': True, 'engages': True, 'targets': True, 'supervision': True, 'fifty': True, 'researching': True, 'battlefield': True, 'weapons': True, 'considered': True, 'dangerous': True, 'reasons': True, 'kill': True, 'innocent': True, 'clear': True, 'held': True, 'accountable': True, 'reliably': True, 'produced': True, 'potentially': True, 'mass': True, 'destruction': True, '30': True, 'china': True, 'supported': True, 'ban': True, 'convention': True, 'conventional': True, 'disagreed.ai': True, 'governments': True, 'smart': True, 'spyware': True, 'voice': True, 'enemies': True, 'hiding': True, 'precisely': True, 'deepfakes': True, 'aid': True, 'producing': True, 'centralized': True, 'competitive': True, 'liberal': True, 'decentralized': True, 'markets.ai': True, 'notably': True, 'bengaluru': True, 'india': True, 'ai-managed': True, 'density': True, 'adjust': True, 'timing': True, 'interval': True, 'needed': True, 'terrorists': True, 'criminals': True, 'rogue': True, 'digital': True, 'warfare': True, 'machine-learning': True, 'tens': True, 'toxic': True, 'molecules': True, 'matter': True, 'technological': True, 'unemployment': True, 'days': True, 'arguments': True, 'put': True, 'forward': True, 'joseph': True, 'weizenbaum': True, 'whether': True, 'done': True, 'computers': True, 'difference': True, 'quantitative': True, 'calculation': True, 'qualitative': True, 'value-based': True, 'judgement.economists': True, 'frequently': True, 'redundancies': True, 'speculated': True, 'adequate': True, 'full': True, 'employment.in': True, 'reduce': True, 'total': True, 'employment': True, 'economists': True, 'acknowledge': True, 'uncharted': True, 'territory': True, 'disagreement': True, 'generally': True, 'agree': True, 'net': True, 'benefit': True, 'productivity': True, 'gains': True, 'redistributed': True, 'estimates': True, 'vary': True, 'michael': True, 'osborne': True, 'carl': True, 'benedikt': True, 'frey': True, 'estimated': True, '47': True, 'jobs': True, 'high': True, 'automation': True, 'oecd': True, 'report': True, '9': True, 'methodology': True, 'speculating': True, 'levels': True, 'criticised': True, 'lacking': True, 'evidential': True, 'foundation': True, 'implying': True, 'creates': True, 'redundancies.unlike': True, 'waves': True, 'middle-class': True, 'eliminated': True, 'economist': True, 'stated': True, 'worry': True, 'white-collar': True, 'steam': True, 'blue-collar': True, 'industrial': True, 'revolution': True, 'worth': True, 'taking': True, 'paralegals': True, 'food': True, 'cooks': True, 'job': True, 'demand': True, 'care-related': True, 'professions': True, 'ranging': True, 'personal': True, 'healthcare': True, 'clergy.in': True, 'april': True, '70': True, 'chinese': True, 'illlustrators': True, 'existential': True, 'humanity': True, 'irreversibly': True, 'lose': True, 'physicist': True, 'stephen': True, 'hawking': True, 'spell': True, 'end': True, 'scenario': True, 'fiction': True, 'robot': True, 'suddenly': True, 'self-awareness': True, 'sentience': True, 'consciousness': True, 'becomes': True, 'malevolent': True, 'sci-fi': True, 'scenarios': True, 'misleading': True, 'ways': True, 'achieve': True, 'philosopher': True, 'nick': True, 'bostrom': True, 'gives': True, 'almost': True, 'sufficiently': True, 'destroy': True, 'paperclip': True, 'factory': True, 'manager': True, 'stuart': True, 'russell': True, 'household': True, 'tries': True, 'owner': True, 'unplugged': True, 'ca': True, 'fetch': True, 'coffee': True, 'dead': True, 'safe': True, 'superintelligence': True, 'genuinely': True, 'aligned': True, 'morality': True, 'values': True, 'fundamentally': True, 'side': True, '.second': True, 'yuval': True, 'noah': True, 'harari': True, 'argues': True, 'physical': True, 'pose': True, 'parts': True, 'civilization': True, 'ideologies': True, 'money': True, 'economy': True, 'exist': True, 'stories': True, 'billions': True, 'believe': True, 'prevalence': True, 'suggests': True, 'convince': True, 'destructive.the': True, 'amongst': True, 'insiders': True, 'mixed': True, 'sizable': True, 'fractions': True, 'concerned': True, 'unconcerned': True, 'eventual': True, 'superintelligent': True, 'personalities': True, 'bill': True, 'gates': True, 'elon': True, 'musk': True, 'ai.in': True, 'distant': True, 'warrant': True, 'perspective': True, 'research.ai': True, 'pioneers': True, 'fei-fei': True, 'li': True, 'yoshua': True, 'bengio': True, 'breazeal': True, 'rana': True, 'el': True, 'kaliouby': True, 'joy': True, 'buolamwini': True, 'sam': True, 'altman': True, 'issued': True, 'mitigating': True, 'extinction': True, 'global': True, 'priority': True, 'alongside': True, 'societal-scale': True, 'pandemics': True, 'nuclear': True, 'war': True, '.other': True, 'spoke': True, 'favor': True, 'less': True, 'dystopian': True, 'juergen': True, 'schmidhuber': True, 'sign': True, 'emphasising': True, '95': True, 'lives': True, 'longer': True, 'healthier': True, 'easier': True, 'now': True, 'andrew': True, 'ng': True, 'mistake': True, 'fall': True, 'doomsday': True, 'hype': True, 'ai—and': True, 'vested': True, 'interests': True, 'yann': True, 'lecun': True, 'scoffs': True, 'his': True, 'peers': True, 'supercharged': True, 'eventually': True, 'limiting': True, 'options': True, 'embedded': True, 'constitutional': True, 'restricting': True, 'compute': True, 'rewrite': True, 'own': True, 'restrict': True, 'open-source': True, 'vs': True, 'proprietary': True, 'backup': True, 'redundancy': True, 'security': True, 'controlling': True, 'monitoring': True, 'emergency': True, 'shut-off': True, 'simulation': True, 'certification': True, 'vulnerabilities': True, 'material': True, 'access': True, 'issue': True, 'ethical': True, 'alignment': True, 'friendly': True, 'beginning': True, 'eliezer': True, 'yudkowsky': True, 'coined': True, 'developing': True, 'investment': True, 'completed': True, 'risk.machines': True, 'principles': True, 'procedures': True, 'resolving': True, 'dilemmas': True, 'aaai': True, 'symposium': True, '2005.other': True, 'approaches': True, 'wendell': True, 'wallach': True, 'moral': True, 'j.': True, 'three': True, 'provably': True, 'beneficial': True, 'frameworks': True, 'projects': True, 'permissibility': True, 'tested': True, 'designing': True, 'implementing': True, 'framework': True, 'act': True, 'containing': True, 'sum': True, 'alan': True, 'institute': True, 'respect': True, 'dignity': True, 'individual': True, 'connect': True, 'sincerely': True, 'openly': True, 'inclusively': True, 'wellbeing': True, 'everyone': True, 'protect': True, 'justice': True, 'public': True, 'interestother': True, 'developments': True, 'decided': True, 'asilomar': True, 'montreal': True, 'responsible': True, 'ieee': True, 'initiative': True, 'criticisms': True, 'regards': True, 'contributes': True, 'frameworks.promotion': True, 'communities': True, 'affect': True, 'consideration': True, 'implications': True, 'stages': True, 'implementation': True, 'collaboration': True, 'roles': True, 'scientists': True, 'product': True, 'managers': True, 'delivery': True, 'sector': True, 'policies': True, 'promoting': True, 'regulating': True, 'broader': True, 'regulatory': True, 'landscape': True, 'emerging': True, 'jurisdictions': True, 'globally': True, 'index': True, 'stanford': True, 'annual': True, 'ai-related': True, '127': True, 'jumped': True, '37': True, 'alone': True, '2020': True, 'adopted': True, 'dedicated': True, 'strategies': True, 'eu': True, 'member': True, 'released': True, 'national': True, 'canada': True, 'japan': True, 'mauritius': True, 'russian': True, 'federation': True, 'saudi': True, 'arabia': True, 'arab': True, 'emirates': True, 'vietnam': True, 'elaborating': True, 'bangladesh': True, 'malaysia': True, 'tunisia': True, 'partnership': True, 'launched': True, 'stating': True, 'accordance': True, 'rights': True, 'democratic': True, 'confidence': True, 'henry': True, 'kissinger': True, 'eric': True, 'schmidt': True, 'daniel': True, 'huttenlocher': True, 'calling': True, 'commission': True, 'regulate': True, 'governance': True, '10': True, 'advisory': True, 'provide': True, 'company': True, 'executives': True, 'officials': True, 'academics.in': True, 'ipsos': True, 'attitudes': True, 'towards': True, 'varied': True, 'greatly': True, 'country': True, '78': True, 'citizens': True, '35': True, 'americans': True, 'agreed': True, 'drawbacks': True, 'reuters/ipsos': True, 'poll': True, '22': True, 'poses': True, 'fox': True, 'news': True, 'thought': True, 'additional': True, '41': True, 'somewhat': True, 'federal': True, 'versus': True, '13': True, 'responding': True, '8': True, 'safety': True, 'summit': True, 'bletchley': True, 'park': True, 'uk': True, 'discuss': True, 'near': True, 'possibility': True, 'mandatory': True, 'voluntary': True, 'start': True, 'co-operation': True, 'manage': True, 'challenges': True, 'mechanical': True, 'philosophers': True, 'mathematicians': True, 'antiquity': True, 'directly': True, 'shuffling': True, 'symbols': True, '1': True, 'church–turing': True, 'thesis': True, 'along': True, 'concurrent': True, 'discoveries': True, 'cybernetics': True, 'consider': True, 'building': True, 'electronic': True, 'thinking': True, '1941': True, 'circulated': True, 'paper': True, 'earliest': True, 'though': True, 'lost': True, 'recognized': True, 'mccullouch': True, 'pitts': True, 'turing-complete': True, '1943': True, 'influenced': True, 'earlier': True, \"'on\": True, 'computable': True, '1936': True, 'two-state': True, 'boolean': True, \"'neurons\": True, 'apply': True, 'neuronal': True, 'function.the': True, \"'machine\": True, 'referred': True, \"'artificial\": True, 'death': True, '1954.': True, '1950': True, 'papers': True, \"'computing\": True, 'concept': True, 'radio': True, 'broadcasts': True, 'lectures': True, \"'intelligent\": True, 'heretical': True, 'think': True, '?': True, 'panel': True, 'discussion': True, 'calculating': True, '1956': True, 'actively': True, 'pursued': True, 'decade': True, 'britain': True, 'programmes': True, 'written': True, '1951–1952.in': True, '1951': True, 'ferranti': True, 'mark': True, 'university': True, 'manchester': True, 'checkers': True, 'american': True, 'workshop': True, 'dartmouth': True, 'college': True, 'attendees': True, '1960s': True, 'students': True, 'press': True, 'astonishing': True, 'algebra': True, 'theorems': True, 'speaking': True, 'british': True, 'latter': True, '1960s.they': True, 'underestimated': True, 'cut': True, 'off': True, 'response': True, 'sir': True, 'james': True, 'lighthill': True, 'ongoing': True, 'pressure': True, 'congress': True, 'fund': True, 'productive': True, 'minsky': True, 'papert': True, 'book': True, 'perceptrons': True, 'understood': True, 'discrediting': True, 'approach': True, 'altogether': True, 'winter': True, 'period': True, 'followed.in': True, 'revived': True, 'expert': True, 'simulated': True, 'analytical': True, 'skills': True, '1985': True, 'reached': True, 'billion': True, 'dollars': True, 'fifth': True, 'project': True, 'restore': True, 'collapse': True, '1987': True, 'again': True, 'fell': True, 'disrepute': True, 'second': True, 'longer-lasting': True, 'began.many': True, 'doubt': True, 'practices': True, 'imitate': True, 'cognition': True, 'look': True, 'rodney': True, 'brooks': True, 'rejected': True, 'focussed': True, 'move': True, 'judea': True, 'pearl': True, 'lofti': True, 'zadeh': True, 'handled': True, 'reasonable': True, 'guesses': True, 'revival': True, 'connectionism': True, '1990': True, 'successfully': True, 'handwritten': True, 'networks.ai': True, 'gradually': True, 'restored': True, 'reputation': True, '21st': True, 'century': True, 'exploiting': True, 'narrow': True, 'focus': True, 'verifiable': True, 'collaborate': True, 'mathematics': True, '2000': True, '.several': True, 'pursuing': True, 'original': True, 'versatile': True, 'fully': True, '2002': True, 'subfield': True, 'agi': True, 'well-funded': True, '2010s.deep': True, 'dominate': True, 'benchmarks': True, 'abandoned': True, 'improvements': True, 'faster': True, 'cloud': True, 'measured': True, 'publications': True, '50': True, '2015–2019': True, 'wipo': True, 'prolific': True, 'patent': True, 'granted': True, 'patents': True, \"'ai\": True, 'impacts': True, '$': True, 'annually': True, 'invested': True, 'phd': True, 'graduates': True, '800,000': True, '-related': True, 'openings': True, 'existed': True, '2022.': True, 'majority': True, 'occurred': True, 'labs': True, 'research.in': True, 'issues': True, 'catapulted': True, 'center': True, 'stage': True, 'conferences': True, 're-focussed': True, 'careers': True, 'defining': True, 'i': True, 'propose': True, \"'can\": True, 'advised': True, 'thinks': True, 'behaviour': True, 'conversation': True, 'observe': True, 'literally': True, 'notes': True, 'usual': True, 'polite': True, 'norvig': True, 'defined': True, 'acting': True, 'critical': True, 'compares': True, 'aeronautical': True, 'texts': True, \"'machines\": True, 'fly': True, 'pigeons': True, 'fool': True, 'founder': True, 'mccarthy': True, 'definition': True, '.mccarthy': True, 'defines': True, 'marvin': True, 'similarly': True, 'hard': True, 'definitions': True, 'well-defined': True, 'direct': True, 'machine—and': True, 'philosophical': True, 'practitioner': True, 'stipulates': True, 'synthesize': True, 'manifestation': True, 'evaluating': True, 'unifying': True, 'paradigm': True, 'unprecedented': True, 'eclipsed': True, 'business': True, 'mean': True, 'mostly': True, 'soft': True, 'critics': True, 'revisited': True, 'generations': True, 'limits': True, 'gofai': True, 'high-level': True, 'conscious': True, 'highly': True, 'iq': True, 'newell': True, 'simon': True, 'proposed': True, 'symbol': True, 'hypothesis': True, 'failed': True, 'easily': True, 'recognizing': True, 'moravec': True, 'paradox': True, 'easy': True, 'instinctive': True, 'extremely': True, 'hubert': True, 'dreyfus': True, 'expertise': True, 'depends': True, 'unconscious': True, 'instinct': True, 'manipulation': True, 'feel': True, 'ridiculed': True, 'ignored': True, 'came': True, 'him.the': True, 'resolved': True, 'inscrutable': True, 'intuition': True, 'continuing': True, 'attain': True, 'away': True, 'understand': True, 'why': True, 'neuro-symbolic': True, 'attempts': True, 'bridge': True, 'neat': True, 'vs.': True, 'scruffy': True, 'neats': True, 'elegant': True, 'scruffies': True, 'unrelated': True, 'defend': True, 'rigor': True, 'rely': True, 'incremental': True, 'discussed': True, '1970s': True, 'seen': True, 'irrelevant': True, 'elements': True, 'correct': True, 'optimal': True, 'genetic': True, 'tolerant': True, 'imprecision': True, 'uncertainty': True, 'partial': True, 'approximation': True, 'pursue': True, 'lead': True, 'indirectly': True, 'measure': True, 'focusing': True, 'sub-field': True, 'exclusively': True, 'mental': True, 'considers': True, 'internal': True, 'experiences': True, 'external': True, 'mainstream': True, '[': True, 't': True, ']': True, 'equipped': True, 'david': True, 'chalmers': True, 'named': True, 'plans': True, 'controls': True, 'explaining': True, 'feels': True, 'assuming': True, 'truly': True, 'dennett': True, 'illusionism': True, 'says': True, 'illusion': True, 'subjective': True, 'imagine': True, 'color-blind': True, 'red': True, 'looks': True, 'computationalism': True, 'functionalism': True, 'relationship': True, 'identical': True, 'mind–body': True, 'cognitive': True, 'originally': True, 'jerry': True, 'fodor': True, 'hilary': True, 'putnam.philosopher': True, 'searle': True, 'characterized': True, 'appropriately': True, 'thereby': True, 'minds': True, 'counters': True, 'assertion': True, 'room': True, 'argument': True, 'perfectly': True, 'simulates': True, 'suppose': True, 'suffer': True, 'entitle': True, 'hypothetical': True, 'lie': True, 'spectrum': True, 'animal': True, 'centuries': True, 'california': True, 'premature': True, 'singularity': True, 'possess': True, 'surpassing': True, 'brightest': True, 'gifted': True, 'mind.if': True, 'might': True, 'reprogram': True, 'itself': True, 'improving': True, 'i.': True, 'vernor': True, 'vinge': True, '.however': True, 'indefinitely': True, 'follow': True, 's-shaped': True, 'curve': True, 'slowing': True, 'transhumanism': True, 'designer': True, 'hans': True, 'cyberneticist': True, 'kevin': True, 'warwick': True, 'inventor': True, 'ray': True, 'kurzweil': True, 'predicted': True, 'merge': True, 'cyborgs': True, 'either': True, 'idea': True, 'roots': True, 'aldous': True, 'huxley': True, 'robert': True, 'ettinger.edward': True, 'fredkin': True, 'evolution': True, 'samuel': True, 'butler': True, 'darwin': True, '1863': True, 'expanded': True, 'george': True, 'dyson': True, '1998.': True, 'thought-capable': True, 'appeared': True, 'storytelling': True, 'devices': True, 'persistent': True, 'theme': True, 'fiction.a': True, 'trope': True, 'mary': True, 'shelley': True, 'frankenstein': True, 'creation': True, 'masters': True, 'arthur': True, 'c.': True, 'clarke': True, 'stanley': True, 'kubrick': True, '2001': True, 'odyssey': True, '1968': True, 'hal': True, '9000': True, 'murderous': True, 'charge': True, 'spaceship': True, 'terminator': True, '1984': True, 'matrix': True, '1999': True, 'contrast': True, 'rare': True, 'loyal': True, 'gort': True, 'day': True, 'earth': True, 'stood': True, 'bishop': True, 'aliens': True, '1986': True, 'prominent': True, 'culture.isaac': True, 'asimov': True, 'books': True, 'multivac': True, 'series': True, 'super-intelligent': True, 'brought': True, 'lay': True, 'discussions': True, 'familiar': True, 'culture': True, 'useless': True, 'ambiguity.several': True, 'force': True, 'confront': True, 'fundamental': True, 'showing': True, 'appears': True, 'karel': True, 'čapek': True, 'r.u.r.': True, 'a.i': True, 'ex': True, 'machina': True, 'novel': True, 'androids': True, 'dream': True, 'electric': True, 'sheep': True, 'philip': True, 'k.': True, 'dick': True, 'subjectivity': True, 'altered': True, 'created': True, 'contentpages': True, 'displaying': True, 'descriptions': True, 'redirect': True, 'overview': True, 'selection': True, 'technology-enabled': True, 'case-based': True, 'emergent': True, 'exhibiting': True, 'female': True, 'gendering': True, 'glossary': True, 'list': True, 'weak': True, 'wetware': True, 'composed': True, 'organic': True, 'amplification': True, 'augment': True, 'explanatory': True, 'references': True, 'textbooks': True, 'open': True, 'syllabus': True, 'peter': True, '4th': True, 'ed.': True, 'hoboken': True, 'pearson': True, 'isbn': True, '978-0134610993.': True, 'lccn': True, '20190474.': True, 'rich': True, 'elaine': True, 'knight': True, 'nair': True, 'shivashankar': True, 'b': True, '2010': True, '3rd': True, 'delhi': True, 'tata': True, 'mcgraw': True, 'hill': True, '978-0070087705.these': True, '2008': True, 'further': True, 'reading': True, 'links': True, 'encyclopedia': True, 'thomason': True, 'richmond': True, 'zalta': True, 'edward': True, 'n': True, 'bbc': True, 'agar': True, 'alison': True, 'adam': True, '&': True, 'igor': True, 'aleksander': True, 'december': True, '2005': True, 'theranostics': True, 'ai—the': True, 'cancer': True, 'precision': True}\n",
            "\n",
            "Preprocessed Text with Snowball stop words and Porter Stemmer:\n",
            "artifici intellig ( ai ) intellig machin softwar , oppos intellig human live be . field studi comput scienc develop studi intellig machin . machin may call ai . ai technolog wide use throughout industri , govern , scienc . high-profil applic : advanc web search engin ( e.g. , googl search ) , recommend system ( use youtub , amazon , netflix ) , interact via human speech ( googl assist , siri , alexa ) , self-driv car ( e.g. , waymo ) , generat creativ tool ( chatgpt ai art ) , superhuman play an\n",
            "\n",
            "Preprocessed Text with WordNet Lemmatizer:\n",
            "artifici intellig ( ai ) intellig machin softwar , oppos intellig human live be . field studi comput scienc develop studi intellig machin . machin may call ai . ai technolog wide use throughout industri , govern , scienc . high-profil applic : advanc web search engin ( e.g. , googl search ) , recommend system ( use youtub , amazon , netflix ) , interact via human speech ( googl assist , siri , alexa ) , self-driv car ( e.g. , waymo ) , gener creativ tool ( chatgpt ai art ) , superhuman play anal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Naive Bayes without Pre-processing:\n"
      ],
      "metadata": {
        "id": "Fr0xm7jRlfJ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 'geographic' and 'non-geographic' are classes\n",
        "geographic_class = \"geographic\"\n",
        "non_geographic_class = \"non-geographic\"\n",
        "\n",
        "# Training data for Naive Bayes on Bag of Words without pre-processing\n",
        "training_data_bow_raw = [\n",
        "    (fetch_wikipedia_text_with_annotations(\"Verona\", geographic_keywords)[0].lower(), geographic_class),\n",
        "    (fetch_wikipedia_text_with_annotations(\"Artificial intelligence\", non_geographic_keywords)[0].lower(), non_geographic_class),\n",
        "]\n",
        "\n",
        "# Tokenizer function for raw text\n",
        "def get_words_in_raw_text_bow(text):\n",
        "    return word_tokenize(text)\n",
        "\n",
        "# Feature extraction function for raw text\n",
        "def extract_features_raw_bow(text):\n",
        "    return {word: True for word in get_words_in_raw_text_bow(text)}\n",
        "\n",
        "# Prepare the training set without pre-processing for Bag of Words\n",
        "training_set_bow_raw = [(extract_features_raw_bow(text), label) for (text, label) in training_data_bow_raw]\n",
        "\n",
        "# Train the Naive Bayes classifier without pre-processing for Bag of Words\n",
        "naive_bayes_classifier_bow_raw = NaiveBayesClassifier.train(training_set_bow_raw)\n",
        "\n",
        "# Usage without pre-processing for Bag of Words\n",
        "test_text_bow_raw = fetch_wikipedia_text_with_annotations(\"Verona\", geographic_keywords)[0].lower()\n",
        "test_features_bow_raw = extract_features_raw_bow(test_text_bow_raw)\n",
        "classification_bow_raw = naive_bayes_classifier_bow_raw.classify(test_features_bow_raw)\n",
        "\n",
        "print(f\"\\nPredicted class for the test text without pre-processing for Bag of Words: {classification_bow_raw}\")\n",
        "\n",
        "test_text_bow_raw = fetch_wikipedia_text_with_annotations(\"Data Science\", non_geographic_keywords)[0].lower()\n",
        "test_features_bow_raw = extract_features_raw_bow(test_text_bow_raw)\n",
        "classification_bow_raw = naive_bayes_classifier_bow_raw.classify(test_features_bow_raw)\n",
        "\n",
        "print(f\"Predicted class for the test text without pre-processing for Bag of Words: {classification_bow_raw}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spB8S2FxiyX7",
        "outputId": "d205df1f-9c95-48c4-85da-0ee7bb752985"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Predicted class for the test text without pre-processing for Bag of Words: geographic\n",
            "Predicted class for the test text without pre-processing for Bag of Words: non-geographic\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Naive Bayes with Pre-processing:\n"
      ],
      "metadata": {
        "id": "3Ufl3zvIlcm2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training data for Naive Bayes with Snowball stop words and Porter Stemmer\n",
        "training_data_bow_snowball = [\n",
        "    (preprocess_text_with_annotations(fetch_wikipedia_text_with_annotations(\"Verona\", geographic_keywords)[0], geographic_keywords, stop_words=set(stopwords.words('english')), stemmer=snowball_stemmer).lower(), geographic_class),\n",
        "    (preprocess_text_with_annotations(fetch_wikipedia_text_with_annotations(\"Artificial intelligence\", non_geographic_keywords)[0], non_geographic_keywords, stop_words=set(stopwords.words('english')), stemmer=snowball_stemmer).lower(), non_geographic_class),\n",
        "]\n",
        "\n",
        "# Tokenizer function for preprocessed text\n",
        "def get_words_in_preprocessed_text_bow(text):\n",
        "    return word_tokenize(text)\n",
        "\n",
        "# Feature extraction function for preprocessed text\n",
        "def extract_features_preprocessed_bow(text):\n",
        "    return {word: True for word in get_words_in_preprocessed_text_bow(text)}\n",
        "\n",
        "# Prepare the training set with Snowball stop words and Porter Stemmer for Bag of Words\n",
        "training_set_bow_snowball = [(extract_features_preprocessed_bow(text), label) for (text, label) in training_data_bow_snowball]\n",
        "\n",
        "# Train the Naive Bayes classifier with Snowball stop words and Porter Stemmer for Bag of Words\n",
        "naive_bayes_classifier_bow_snowball = NaiveBayesClassifier.train(training_set_bow_snowball)\n",
        "\n",
        "# Usage with Snowball stop words and Porter Stemmer for Bag of Words\n",
        "test_text_bow_snowball = preprocess_text_with_annotations(fetch_wikipedia_text_with_annotations(\"Verona\", geographic_keywords)[0], geographic_keywords, stop_words=set(stopwords.words('english')), stemmer=snowball_stemmer).lower()\n",
        "test_features_bow_snowball = extract_features_preprocessed_bow(test_text_bow_snowball)\n",
        "classification_bow_snowball = naive_bayes_classifier_bow_snowball.classify(test_features_bow_snowball)\n",
        "\n",
        "print(f\"\\nPredicted class for the preprocessed test text with Snowball stop words and Porter Stemmer for Bag of Words: {classification_bow_snowball}\")\n",
        "\n",
        "test_text_bow_snowball = preprocess_text_with_annotations(fetch_wikipedia_text_with_annotations(\"Data Science\", non_geographic_keywords)[0], non_geographic_keywords, stop_words=set(stopwords.words('english')), stemmer=snowball_stemmer).lower()\n",
        "test_features_bow_snowball = extract_features_preprocessed_bow(test_text_bow_snowball)\n",
        "classification_bow_snowball = naive_bayes_classifier_bow_snowball.classify(test_features_bow_snowball)\n",
        "\n",
        "print(f\"Predicted class for the preprocessed test text with Snowball stop words and Porter Stemmer for Bag of Words: {classification_bow_snowball}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPPWbBaWlaE-",
        "outputId": "fd0380ba-6be9-4831-e2dd-fb2d0d097739"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Predicted class for the preprocessed test text with Snowball stop words and Porter Stemmer for Bag of Words: geographic\n",
            "Predicted class for the preprocessed test text with Snowball stop words and Porter Stemmer for Bag of Words: non-geographic\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Logistic Regression"
      ],
      "metadata": {
        "id": "Ix6gFTaPmmWF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training data for Logistic Regression with pre-processing from Naive Bayes\n",
        "training_data_logistic_preprocessed = [\n",
        "    (preprocess_text_with_annotations(fetch_wikipedia_text_with_annotations(\"Verona\", geographic_keywords)[0], geographic_keywords, stop_words=set(stopwords.words('english')), stemmer=snowball_stemmer).lower(), geographic_class),\n",
        "    (preprocess_text_with_annotations(fetch_wikipedia_text_with_annotations(\"Artificial intelligence\", non_geographic_keywords)[0], non_geographic_keywords, stop_words=set(stopwords.words('english')), stemmer=snowball_stemmer).lower(), non_geographic_class),\n",
        "]\n",
        "\n",
        "# Tokenizer function for preprocessed text (same as used for Naive Bayes)\n",
        "def get_words_in_preprocessed_text_logistic(text):\n",
        "    return word_tokenize(text)\n",
        "\n",
        "# Feature extraction function for preprocessed text (same as used for Naive Bayes)\n",
        "def extract_features_preprocessed_logistic(text):\n",
        "    return ' '.join(get_words_in_preprocessed_text_logistic(text))\n",
        "\n",
        "# Prepare the training set for Logistic Regression with pre-processing\n",
        "training_set_logistic_preprocessed = [(extract_features_preprocessed_logistic(text), label) for (text, label) in training_data_logistic_preprocessed]\n",
        "\n",
        "# Create TF-IDF vectors from the training set for Logistic Regression with pre-processing\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Separate features (X) and labels (y) for Logistic Regression with pre-processing\n",
        "X_train_logistic_preprocessed = [text for (text, _) in training_set_logistic_preprocessed]\n",
        "y_train_logistic_preprocessed = [label for (_, label) in training_set_logistic_preprocessed]\n",
        "\n",
        "# Create TF-IDF vectors from the training set for Logistic Regression with pre-processing\n",
        "tfidf_vectorizer_logistic_preprocessed = TfidfVectorizer()\n",
        "X_train_tfidf_logistic_preprocessed = tfidf_vectorizer_logistic_preprocessed.fit_transform(X_train_logistic_preprocessed)\n",
        "\n",
        "# Train the Logistic Regression classifier with pre-processing\n",
        "logistic_regression_classifier_preprocessed = LogisticRegression()\n",
        "logistic_regression_classifier_preprocessed.fit(X_train_tfidf_logistic_preprocessed, y_train_logistic_preprocessed)\n",
        "\n",
        "# Usage for Logistic Regression with pre-processing\n",
        "test_text_logistic_preprocessed = preprocess_text_with_annotations(fetch_wikipedia_text_with_annotations(\"Verona\", geographic_keywords)[0], geographic_keywords, stop_words=set(stopwords.words('english')), stemmer=snowball_stemmer).lower()\n",
        "test_features_logistic_preprocessed = tfidf_vectorizer_logistic_preprocessed.transform([extract_features_preprocessed_logistic(test_text_logistic_preprocessed)])\n",
        "classification_logistic_preprocessed = logistic_regression_classifier_preprocessed.predict(test_features_logistic_preprocessed)\n",
        "\n",
        "print(f\"\\nPredicted class for the test text using Logistic Regression with pre-processing: {classification_logistic_preprocessed[0]}\")\n",
        "\n",
        "test_text_logistic_preprocessed = preprocess_text_with_annotations(fetch_wikipedia_text_with_annotations(\"Data Science\", non_geographic_keywords)[0], non_geographic_keywords, stop_words=set(stopwords.words('english')), stemmer=snowball_stemmer).lower()\n",
        "test_features_logistic_preprocessed = tfidf_vectorizer_logistic_preprocessed.transform([extract_features_preprocessed_logistic(test_text_logistic_preprocessed)])\n",
        "classification_logistic_preprocessed = logistic_regression_classifier_preprocessed.predict(test_features_logistic_preprocessed)\n",
        "\n",
        "print(f\"Predicted class for the test text using Logistic Regression with pre-processing: {classification_logistic_preprocessed[0]}\")\n",
        "\n",
        "# Training data for Logistic Regression without pre-processing\n",
        "training_data_logistic_raw = [\n",
        "    (fetch_wikipedia_text_with_annotations(\"Verona\", geographic_keywords)[0].lower(), geographic_class),\n",
        "    (fetch_wikipedia_text_with_annotations(\"Artificial intelligence\", non_geographic_keywords)[0].lower(), non_geographic_class),\n",
        "]\n",
        "\n",
        "# Tokenizer function for raw text (same as used for Naive Bayes)\n",
        "def get_words_in_raw_text_logistic(text):\n",
        "    return word_tokenize(text)\n",
        "\n",
        "# Feature extraction function for raw text (same as used for Naive Bayes)\n",
        "def extract_features_raw_logistic(text):\n",
        "    return ' '.join(get_words_in_raw_text_logistic(text))\n",
        "\n",
        "# Prepare the training set for Logistic Regression without pre-processing\n",
        "training_set_logistic_raw = [(extract_features_raw_logistic(text), label) for (text, label) in training_data_logistic_raw]\n",
        "\n",
        "# Create TF-IDF vectors from the training set for Logistic Regression without pre-processing\n",
        "X_train_logistic_raw = [text for (text, _) in training_set_logistic_raw]\n",
        "y_train_logistic_raw = [label for (_, label) in training_set_logistic_raw]\n",
        "\n",
        "tfidf_vectorizer_logistic_raw = TfidfVectorizer()\n",
        "X_train_tfidf_logistic_raw = tfidf_vectorizer_logistic_raw.fit_transform(X_train_logistic_raw)\n",
        "\n",
        "# Train the Logistic Regression classifier without pre-processing\n",
        "logistic_regression_classifier_raw = LogisticRegression()\n",
        "logistic_regression_classifier_raw.fit(X_train_tfidf_logistic_raw, y_train_logistic_raw)\n",
        "\n",
        "# Usage for Logistic Regression without pre-processing\n",
        "test_text_logistic_raw = fetch_wikipedia_text_with_annotations(\"Verona\", geographic_keywords)[0].lower()\n",
        "test_features_logistic_raw = tfidf_vectorizer_logistic_raw.transform([extract_features_raw_logistic(test_text_logistic_raw)])\n",
        "classification_logistic_raw = logistic_regression_classifier_raw.predict(test_features_logistic_raw)\n",
        "\n",
        "print(f\"\\nPredicted class for the test text using Logistic Regression without pre-processing: {classification_logistic_raw[0]}\")\n",
        "\n",
        "test_text_logistic_raw = fetch_wikipedia_text_with_annotations(\"Data Science\", non_geographic_keywords)[0].lower()\n",
        "test_features_logistic_raw = tfidf_vectorizer_logistic_raw.transform([extract_features_raw_logistic(test_text_logistic_raw)])\n",
        "classification_logistic_raw = logistic_regression_classifier_raw.predict(test_features_logistic_raw)\n",
        "\n",
        "print(f\"Predicted class for the test text using Logistic Regression without pre-processing: {classification_logistic_raw[0]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ss31yG5KlyW5",
        "outputId": "b542cf29-4c44-45d4-a72b-76f8489c2384"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Predicted class for the test text using Logistic Regression with pre-processing: geographic\n",
            "Predicted class for the test text using Logistic Regression with pre-processing: non-geographic\n",
            "\n",
            "Predicted class for the test text using Logistic Regression without pre-processing: geographic\n",
            "Predicted class for the test text using Logistic Regression without pre-processing: non-geographic\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HtOG8EsJmoPD"
      },
      "execution_count": 9,
      "outputs": []
    }
  ]
}